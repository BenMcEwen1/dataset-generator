{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d59d1ba",
   "metadata": {},
   "source": [
    "# BaseAL Dataset Generator\n",
    "\n",
    "Generates a dataset in a BaseAL friendly format.\n",
    "\n",
    "**Pipeline:**\n",
    "1. Split audio into fixed-length segments (length dependent on model selected)\n",
    "2. Generate embeddings per segment using pretrained models (BirdNET, Perch, etc.) - using bacpipe\n",
    "3. Convert onset/offset labels to per-segment labels\n",
    "4. Package into BaseAL format\n",
    "\n",
    "**Required Format:**\n",
    "```\n",
    "dataset_name/\n",
    "├── data/\n",
    "|   ├── birdnet/\n",
    "│   |   ├── file1_000_003.wav\n",
    "│   |   ├── file1_003_006.wav\n",
    "|   |   ├── ...\n",
    "│   └── perch_v2/\n",
    "│       └── ...\n",
    "├── embeddings/\n",
    "│   ├── birdnet/\n",
    "│   │   ├── file1_000_003_birdnet.npy\n",
    "│   │   └── ...\n",
    "│   └── perch_v2/\n",
    "│       └── ...\n",
    "├── labels.csv        # filename, label, validation\n",
    "└── metadata.csv      # All segment metadata\n",
    "```\n",
    "\n",
    "***Important - each row is a segment/embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57in9kf18f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from utils.helpers import convert_for_json\n",
    "from utils.embeddings import initialise, generate_embeddings\n",
    "from utils.adapters import HSNAdapter, AdapterConfig\n",
    "from utils.segment_labels import (\n",
    "    split_metadata_with_adapter,\n",
    "    create_labels_csv_with_adapter,\n",
    "    SegmentConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51dc1bd",
   "metadata": {},
   "source": [
    "## Generate Segments and Embeddings\n",
    "\n",
    "This uses bacpipe which automatically manages and downloads models, generates audio segments, and embeddings.\n",
    "\n",
    "*More info on bacpipe [here](https://github.com/bioacoustic-ai/bacpipe/releases/tag/v1.2.0)*\n",
    "\n",
    "I have provided an example with a single BirdSet HSN shard and a small subset for testing. There were conflicting dependencies with datasets (huggingface) and bacpipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d34cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify model\n",
    "MODEL = \"birdnet\"\n",
    "\n",
    "# perch_v2 only runs on Linux/WSL\n",
    "\n",
    "# Audio path\n",
    "AUDIO_PATH = Path(\"HSN/HSN_train_shard_0001\")\n",
    "METADATA_PATH = Path(\"HSN/HSN_metadata_train.parquet\")\n",
    "\n",
    "# Dataset paths\n",
    "DATASET_PATH = Path(\"HSN_BASEAL\")\n",
    "DATASET_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "SEG_PATH = DATASET_PATH / \"data\" / MODEL\n",
    "EMB_PATH = DATASET_PATH / \"embeddings\" / MODEL\n",
    "SEG_PATH.mkdir(exist_ok=True, parents=True)\n",
    "EMB_PATH.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Validation configuration\n",
    "VALIDATION_FRACTION = 0.1\n",
    "\n",
    "embedder = initialise(model_name=MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9affa5",
   "metadata": {},
   "source": [
    "Generate audio segments and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = generate_embeddings(\n",
    "    audio_dir=AUDIO_PATH,\n",
    "    embedder=embedder,\n",
    "    model_name=MODEL,\n",
    "    segments_dir=SEG_PATH,\n",
    "    output_dir=EMB_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b32ea6c",
   "metadata": {},
   "source": [
    "## Labels and Metadata\n",
    "\n",
    "Use the HSNAdapter to load metadata and create segment-level labels.\n",
    "\n",
    "The adapter handles:\n",
    "- Loading HSN's parquet metadata format\n",
    "- Combining `ebird_code_multilabel` + `ebird_code_secondary` as labels\n",
    "- Extracting `detected_events` onset/offset annotations\n",
    "- Random validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the adapter\n",
    "adapter_config = AdapterConfig(\n",
    "    validation_fraction=VALIDATION_FRACTION,\n",
    "    random_seed=42,\n",
    "    no_event_label=\"no_call\"\n",
    ")\n",
    "\n",
    "# Create the HSN adapter\n",
    "adapter = HSNAdapter(config=adapter_config)\n",
    "\n",
    "# Load metadata\n",
    "df = adapter.load_metadata(METADATA_PATH)\n",
    "print(f\"Original: {len(df)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe743610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get segment duration from model\n",
    "duration = embedder.model.segment_length / embedder.model.sr\n",
    "\n",
    "# Configure segmentation\n",
    "config = SegmentConfig(\n",
    "    segment_duration=duration,\n",
    "    min_overlap=0.0,\n",
    "    no_event_label=\"no_call\"\n",
    ")\n",
    "\n",
    "# Split into segments using the adapter\n",
    "segment_df = split_metadata_with_adapter(df, adapter, config)\n",
    "print(f\"Segments: {len(segment_df)} ({segment_df['has_event'].sum()} with events)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0a474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to JSON strings to avoid embedded newlines\n",
    "csv_df = segment_df.copy()\n",
    "for col in ['segment_events', 'segment_event_clusters', 'ebird_code_multilabel', 'ebird_code_secondary']:\n",
    "    if col in csv_df.columns:\n",
    "        csv_df[col] = csv_df[col].apply(lambda x: json.dumps(convert_for_json(x)))\n",
    "csv_df.to_csv(DATASET_PATH / \"metadata.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "# Create labels.csv with validation split using adapter\n",
    "labels_df = create_labels_csv_with_adapter(segment_df, adapter)\n",
    "labels_df.to_csv(DATASET_PATH / \"labels.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Saved metadata to {DATASET_PATH / 'metadata.csv'}\")\n",
    "print(f\"Saved labels to {DATASET_PATH / 'labels.csv'}\")\n",
    "print(f\"\\nValidation split:\")\n",
    "print(f\"  Train: {(~labels_df['validation']).sum()} segments\")\n",
    "print(f\"  Validation: {labels_df['validation'].sum()} segments\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
